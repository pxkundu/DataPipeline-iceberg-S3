# ğŸš€ Apache Iceberg with AWS S3 & Athena

## ğŸ“Œ Overview
This project demonstrates how to use **Apache Iceberg** with **AWS S3, AWS Glue, and AWS Athena** to create a modern, efficient, and scalable **data lakehouse**.

### **ğŸ”¹ Features**
- âœ… **ACID Transactions** on AWS S3 using Iceberg
- âœ… **Schema Evolution** (add, rename, drop columns)
- âœ… **Time Travel** queries with historical snapshots
- âœ… **Partition Evolution** for optimized query performance
- âœ… **Integration with AWS Athena, Glue, and Terraform**

---

## ğŸ“‚ Project Structure
.
â”œâ”€â”€ infrastructure   # Terraform scripts for AWS setup
â”‚   â”œâ”€â”€ main.tf
â”‚   â”œâ”€â”€ glue_catalog.tf
â”‚   â”œâ”€â”€ s3_bucket.tf
â”‚   â”œâ”€â”€ athena_iceberg.tf
â”‚   â”œâ”€â”€ variables.tf
â”œâ”€â”€ sql_queries      # SQL scripts for table creation & querying
â”‚   â”œâ”€â”€ create_database.sql
â”‚   â”œâ”€â”€ create_table.sql
â”‚   â”œâ”€â”€ insert_data.sql
â”‚   â”œâ”€â”€ query_data.sql
â”‚   â”œâ”€â”€ time_travel.sql
â”‚   â”œâ”€â”€ schema_evolution.sql
â”‚   â”œâ”€â”€ optimize_table.sql
â”œâ”€â”€ scripts          # Python scripts for data automation
â”‚   â”œâ”€â”€ s3_upload.py
â”‚   â”œâ”€â”€ iceberg_query.py
â”‚   â”œâ”€â”€ optimize_table.py
â”œâ”€â”€ notebooks        # Jupyter Notebook for interactive demo
â”‚   â”œâ”€â”€ Iceberg_Demo.ipynb
â”œâ”€â”€ config           # Configuration files
â”‚   â”œâ”€â”€ aws_config.json
â”‚   â”œâ”€â”€ glue_crawler_config.json
â”‚   â”œâ”€â”€ iceberg_table_properties.json
â”œâ”€â”€ data             # Sample dataset
â”‚   â”œâ”€â”€ sample_data.csv
â”œâ”€â”€ docs             # Documentation
â”‚   â”œâ”€â”€ setup_guide.md
â”‚   â”œâ”€â”€ architecture_diagram.png
â”‚   â”œâ”€â”€ troubleshooting.md
â””â”€â”€ README.md        # Project documentation

---

## ğŸš€ **Setup Guide**
### **ğŸ”¹ 1ï¸âƒ£ Prerequisites**
- **AWS CLI** configured with valid credentials
- **Terraform** installed (`terraform -v`)
- **Python 3** with `boto3` installed (`pip install boto3`)
- **Athena Workgroup** & **S3 Bucket** created

### **ğŸ”¹ 2ï¸âƒ£ Provision AWS Infrastructure**
Run the following commands to create **S3, AWS Glue, and Athena** resources using Terraform:

```sh
cd infrastructure
terraform init
terraform apply
```
**Resources created:**
- `S3 Bucket` for Iceberg data lake (`s3://my-iceberg-data-lake/`)
- `AWS Glue Database` (`iceberg_db`)
- `Athena Workgroup` for querying Iceberg tables

---

## ğŸ› ï¸ **Usage Instructions**
### **ğŸ”¹ 3ï¸âƒ£ Upload Sample Data to S3**
```sh
python scripts/s3_upload.py
```

---

### **ğŸ”¹ 4ï¸âƒ£ Create Iceberg Table**
Run the following **SQL script in Athena**:
```sql
CREATE TABLE iceberg_db.sales_data (
    order_id BIGINT,
    customer_name STRING,
    total_amount DOUBLE,
    order_date TIMESTAMP
)
LOCATION 's3://my-iceberg-data-lake/sales_data/'
TBLPROPERTIES (
    'table_type'='ICEBERG',
    'format'='parquet'
);
```

---

### **ğŸ”¹ 5ï¸âƒ£ Insert Data**
```sql
INSERT INTO iceberg_db.sales_data VALUES
    (1, 'Alice', 250.50, TIMESTAMP '2024-02-02 10:00:00'),
    (2, 'Bob', 300.75, TIMESTAMP '2024-02-02 11:15:00');
```

---

### **ğŸ”¹ 6ï¸âƒ£ Query Iceberg Table via Athena**
```sql
SELECT * FROM iceberg_db.sales_data;
```

OR using Python:
```sh
python scripts/iceberg_query.py
```

---

## ğŸ“Œ **Advanced Features**
### **ğŸ”¹ 7ï¸âƒ£ Time Travel Queries**
Apache Iceberg stores snapshots of your table. Use **Time Travel Queries** to view historical data.

1ï¸âƒ£ **List available snapshots**:
```sql
SELECT * FROM iceberg_db.sales_data$snapshots;
```
2ï¸âƒ£ **Query a previous snapshot**:
```sql
SELECT * FROM iceberg_db.sales_data FOR SYSTEM_VERSION AS OF 123456789;
```
*(Replace `123456789` with a valid snapshot ID)*

---

### **ğŸ”¹ 8ï¸âƒ£ Schema Evolution**
Modify table schema **without rewriting the entire dataset**.

- **Add a new column**:
```sql
ALTER TABLE iceberg_db.sales_data ADD COLUMNS (customer_email STRING);
```
- **Rename a column**:
```sql
ALTER TABLE iceberg_db.sales_data RENAME COLUMN total_amount TO total_price;
```
- **Drop a column**:
```sql
ALTER TABLE iceberg_db.sales_data DROP COLUMN customer_name;
```

---

### **ğŸ”¹ 9ï¸âƒ£ Optimize Table Performance**
Iceberg manages **small files** and **table compaction**.

**Manually trigger optimization**:
```sql
CALL iceberg.system.rewrite_data_files('iceberg_db.sales_data');
```

---

## ğŸ›  **Troubleshooting**
If you encounter **Athena query failures**, check:
1. AWS Glue **database and table names** are correctly set.
2. The **S3 location** for Iceberg tables is correct (`s3://my-iceberg-data-lake/`).
3. **Permissions**:
   - AWS Glue IAM role has `AthenaQueryExecution` permissions.
   - S3 bucket allows **Athena read/write access**.

More details in ğŸ“ `docs/troubleshooting.md`.

---

## ğŸ“Œ **Comparison: Iceberg vs Delta Lake vs Hudi**
| Feature          | Apache Iceberg | Delta Lake | Apache Hudi |
|-----------------|---------------|------------|-------------|
| **ACID Transactions** | âœ… Yes | âœ… Yes | âœ… Yes |
| **Schema Evolution** | âœ… Yes | âœ… Yes | ğŸŸ  Partial |
| **Partition Evolution** | âœ… Yes | âŒ No | âŒ No |
| **Time Travel** | âœ… Yes | âœ… Yes | ğŸŸ  Limited |
| **AWS Glue Support** | âœ… Yes | âœ… Yes | âŒ No |

---

## ğŸ¯ **Next Steps**
- âœ… **Integrate with Apache Spark for batch processing**
- âœ… **Deploy AWS Lambda for real-time data ingestion**
- âœ… **Automate deployment using GitHub Actions**
- âœ… **Connect Iceberg with AWS EMR & Redshift Spectrum**

---

## ğŸ“œ **License**
This project is licensed under the **MIT License**.

---

## â­ **Support & Contributions**
ğŸ”¹ Found this useful? **Give a star â­ on GitHub!**  
ğŸ”¹ Want to contribute? **Fork and submit a PR!**  

ğŸ“© **Need Help?** Contact via **GitHub Issues**.

---

### **ğŸš€ Happy Data Engineering with Apache Iceberg & AWS! ğŸ‰**
```

---

## **ğŸš€ Next Steps**
1. **GitHub Actions workflow** to automate deployment
2. **Need an architecture diagram for documentation**

